% Set the author and title of the compiled pdf
\hypersetup{
	pdftitle = {\Title},
	pdfauthor = {\Author}
}

% Gives us a dot to use in parse trees. The phantom '|' symbols aren't shown but
% give us vertical (and a little bit of horizontal) space so the parse tree has
% the correct spacing.
\newcommand{\parsetreedot}{\phantom{|}\cdot\phantom{|}}

\section{Discrete Structures}

\subsection{Terminology}

A {\it structure} consists of certain {\it sets}. It also contains {\it
elements} of these sets, {\it operations} on these sets and {\it relations} on
these sets.

\subsection{Number systems to learn}

The following number must be learnt:

\begin{center}
	\begin{tabularx}{\textwidth}{l X}
		$\mathbb{N}$ & The set of natural numbers (all whole numbers from $0$ to $\infty$)\\

		$\mathbb{Z}$ & The set of integers (all whole numbers from $-\infty$ to $\infty$)\\

		$\mathbb{Q}$ & The set of rational numbers (any integer divided by any other integer e.g. $\frac{5}{4}=1.25$)\\

		$\mathbb{R}$ & The set of real numbers (all finite and infinite decimal numbers)\\
	\end{tabularx}
\end{center}

\subsubsection{Operations}

Each number system has a set of valid operations that can be performed on
elements in that system. Number systems only contain operations that will
produce an output that is still within the number system.

For example, the number system $\mathbb{N}$ contains the operations of addition
and multiplication. This is because the summation of any two positive integers
will {\it always} be a member of $\mathbb{N}$, and the same goes for
multiplication.

However, you may be wondering why subtraction and division aren't included in
this number system. This is because for some numbers, the result of subtraction
or division won't be inside the set $\mathbb{N}$. An example of this would be
subtracting $4$ from $2$. Even though both of the operands are inside
$\mathbb{N}$, the answer isn't.

Different sets may have different operations available. For example, you can
concentrate any two members of the set $\mathbb{S}tring$ and end up with another
$\mathbb{S}tring$.

\paragraph{Types of operation} Operations that have an operand either side of
them are called {\it infix} operations. An example of an infix operation is
addition. Infix operations are also referred to as {\it binary} operations since
they have {\it two} operands.

\paragraph{Commutativity} If an operation is commutative, the order of the
operands doesn't matter. For example, addition is commutative since:

\begin{dmath}
	a + b = b + a
\end{dmath}

Subtraction however, isn't commutative:

\begin{dmath}
	a - b \neq b - a
\end{dmath}

\paragraph{Associativity}

An operation is associative if inserting or changing brackets doesn't change the
outcome of the operation. For example, multiplication is associative since:

\begin{dmath}
	(a \times b) \times c = a \times (b \times c)
\end{dmath}

An operation may only be commutative or associative if it is commutative or
associative for {\it all} elements of the set that the operation supports.

\paragraph{Distinguished elements}

A set may contain distinguished elements that have strange effects on certain
operations in the set. An example is the number 1. If we multiply {\it
something} by 1, then the result will always be the same {\it something}. The
same goes for 0 with addition. Because of this, we refer to 1 and 0 as
distinguished elements of the set $\mathbb{Z}$.

\subsubsection{Relations}

Each of the sets $\mathbb{N, Q, Q, R}$ carries binary comparison relations
$\leq$ and $<$. Different sets (such as $\mathbb{S}tring$) may have other
relations, such as:

\begin{itemize}
	\item Is a section of
	\item Is an initial section of
	\item Occurs in
\end{itemize}

All relations return values in the set $\mathbb{B}ool$.

\subsection{Bases}

Conventionally, we count using base 10. Base 10 includes, you guessed it, ten
different symbols from 0 through to 9.

Sometimes however, it is convenient to count using different bases. Popular
bases include:

\begin{center}
	\begin{tabular}{l l l}
		{\bf Base $n$} & {\bf Member symbols} & {\bf Name}\\
		$n = 2$ & $\mathbb{Z}_2 = \{0, 1\}$ & Binary\\
		$n = 8$ & $\mathbb{Z}_8 = \{0, 1, 2, 3, 4, 5, 6, 7\}$ & Octal\\
		$n = 10$ & $\mathbb{Z}_{10} = \{0, 1, \ldots, 7\}$ & Decimal\\
		$n = 16$ & $\mathbb{Z}_{16} = \{0-9, A-F\}$ & Hexadecimal\\
	\end{tabular}
\end{center}

\subsubsection{How to read numbers in any given base}

The formula for reading a number in a given base is as follows:

\begin{dmath}
	\sum_{i=0}^{k}a_{i}b^{i}
\end{dmath}

Where the number you're trying to read takes the form $a_k, a_{k-1}, \ldots, a_2, a_1, a_0$ and $b$ is the base you're using.

\paragraph{Example 1}

Lets apply the formula to the base 10 number $27385$:

\begin{dmath}
		27385 = (5 \times 10^0) + (8 \times 10^1) + (3 \times 10^2) + (7 \times 10^3) + (2 \times 10^4)
		      = (5 \times 1) + (8 \times 10) + (3 \times 100) + (7 \times 1000) + (2 \times 10000)
		      = 5 + 80 + 300 + 7000 + 20000
		      = 27385
\end{dmath}

\paragraph{Example 2}

Lets apply the formula to the base 16 number $F00BA4$:


\begin{dmath}
	F00BA4 = (4 \times 16^0) + (A \times 16^1) + (B \times 16^2) + (0 \times 16^3) + (0 \times 16^4) + (F \times 16^5)
	       = (4 \times 16^0) + (10 \times 16) + (11 \times 256) + (0 \times 4096) + (0 \times 65536) + (15 \times 1048576)
	       = 4 + 160 + 2816 + 0 + 0 + 15728640
	       = 15731620
\end{dmath}

\subsubsection{Changing from base 10 to base $n$}

In order to change into base $n$ from base 10, we just repeatedly divide by $n$
and use the remainder as the value for base $n$. Here are a few examples:

\paragraph{Example 1}
Convert 893 into base 2.

\begin{center}
	\begin{tabular} {r l l l }
		$893 \div 2$ & = & 446 & r1\\
		$446 \div 2$ & = & 223 & r0\\
		$223 \div 2$ & = & 111 & r1\\
		$111 \div 2$ & = & 55 & r1\\
		$55 \div 2$ & = & 27 & r1\\
		$27 \div 2$ & = & 13 & r1\\
		$13 \div 2$ & = & 6 & r1\\
		$6 \div 2$ & = & 3 & r0\\
		$3 \div 2$ & = & 1 & r1\\
		$1 \div 2$ & = & 0 & r1\\
	\end{tabular}
\end{center}

Reading up from the bottom, we can see that the binary (base 2) representation
is $1101111101$.

\paragraph{Example 2}
Convert 893 into base 9.

\begin{center}
	\begin{tabular} {r l l l }
		$893 \div 9$ & = & 99 & r2\\
		$99 \div 9$ & = & 11 & r0\\
		$11 \div 9$ & = & 1 & r2\\
		$1 \div 9$ & = & 0 & r1\\
	\end{tabular}
\end{center}

Reading up from the bottom, we can see that the nonal (base 9) representation is
$1202$.

\paragraph{Example 2}
Convert 893 into base 16.

\begin{center}
	\begin{tabular} {r l l l }
		$893 \div 16$ & = & 55 & r13\\
		$55 \div 16$ & = & 3 & r7\\
		$3 \div 16$ & = & 0 & r3\\
	\end{tabular}
\end{center}

Reading up from the bottom, we can see that the hexadecimal (base 16)
representation is $3,7,13$ or $37D$.

\subsection{A structure for the integers}

The set $\mathbb{Z}$ of all integers $\ldots,-3,-2,-1,0,1,2,3,\ldots$ includes
the subset $\mathbb{N}$ of all natural numbers together with the negative
integers. We will be using three basic binary operations on the carrier set
$\mathbb{Z}$: addition, multiplication and subtraction.

The standard notation for these operations is $+$, $\times$ and $-$ and they are
used as infix operations.

Sometimes different notations are used, for example, in programming * is usually
used, or there is a convention to write $xy$ as an abbreviation for $x \times
y$.
 
Both + and x are {\bf commutative} but - is not.

\begin{enumerate}
\item For all integers {\it x,y} both, $x + y = y + x$ and $xy = yx$
\item There are integers {\it x,y} with $x - y \ne y - x$.
\end{enumerate}

Commutativity ensures that for most purposes the order in which the two
arguments are consumed is irrelevant.

Both + and x are {\bf associative} but - is not.

\begin{enumerate}
\item For all integers {\it x,y,z} both $(x + y) + z = x + (y + z)$ , $(xy)z = x(yz)$.
\item There are integers {\it x,y,z} with $(x - y) - z \ne x - (y - z)$.
\end{enumerate}

Associativity ensures that for most purposes brackets are not needed to
punctuate an expression. For instance, we can make sense of {\it x + y + z} and
{\it xyz} since it doesn't matter where the brackets are, the resulting values
are the same.

Below are the definitions of commutativity and associativity.

\marginpar{ N.b. Commutativity and associativity don't always have to go
together. An example is the average of two numbers, what is that?}

\begin{enumerate}
  \item 
    $\circledast$ is {\bf commutative} if and only if
    \begin{dmath}
	a1 \circledast a2 = a2 \circledast a1
    \end{dmath} 
    for all $a1,a2,\in,A$
  \item 
    $\circledast$ is {\bf associative} if and only if
    \begin{dmath}
	(a1 \circledast a2) \circledast a3 = a1 \circledast (a2 \circledast a3)
    \end{dmath} 
    for all $a1,a2,a3,\in,A$
\end{enumerate}

Some numbers have special effects on operations in a set. Some examples are $0$
and $1$. When $0$ is added to a number, the result is still that number, and
when multiplying a number by $1$, the result is still that number. This means
for the set $\mathbb{Z}$, $0$ and $1$ are neutral elements for the operations
addition and multiplication respectively.

\subsection{The formal language}

We use the formal language to talk about $\mathbb{Z}$. Expressions in the formal
language are built up from atoms in a recursive fashion, so an expression may be
$(x \circ y)$ where $x$ and $y$ are expressions and $\circ$ is one of the three
operations ($+, -, \times$). The brackets are important in the formal language,
since they ensure that strings can only be parsed in one way.

Strings that contain literals that aren't neutral elements or have invalid
bracketing are not valid in the formal language. Examples may include:

\begin{dmath}
	(x + y + z)\\
\end{dmath}
\begin{dmath}
	(x + 2)\\
\end{dmath}
\begin{dmath}
	x((y
\end{dmath}

We can use a parse tree to show how an expression is built up from it's
identifiers ($a, b, c\ldots$), constants ($0, 1\ldots$) and operations ($+, -,
\times\ldots$).

For example, the parse tree of $(x \times (y + z))$ is:

% See my SE question for more on these parse trees:
% http://tex.stackexchange.com/questions/141264/drawing-parse-trees

\begin{dmath}
	\infer[(\times)]{(x \times (y + z))}{
		x
		&
		\infer[(+)]{(y + z)}{
			y
			&
			z
		}
	}
\end{dmath}

Often, especially with large parse trees, it's a pain to write so many
identifiers. Because of this, it is a convention to replace identifiers with
dots after they've been used once, like so:

\begin{dmath}
	\infer[(\times)]{\parsetreedot} {
		x
		&
		\infer[(+)]{\parsetreedot} {
			y
			&
			z
		}
	}
\end{dmath}

In order to parse a parse tree, we must assign an appropriate value to each of
the 'leaves' of the tree (i.e. all the identifiers) and let the values trickle
down towards the root node of the tree where the evaluated answer will appear.

Lets use the above example again. Let $x = 4$, $y = 6$ and $z = 2$:

\begin{dmath}
	\infer[(\times)]{32} {
		4
		&
		\infer[(+)]{8} {
			6
			&
			2
		}
	}
\end{dmath}

\marginpar{ The infix notation is when an operator is placed between two
operands, e.g. $2 + 2$. Other notations include the {\it prefix} and {\it
postfix} notations.}

At this point, parse trees may seem very pointless, but this is because we're
doing very simple arithmetic. However, when we start to define other operators
that do unfamiliar things or don't use the {\it infix} notation,
then using parse trees can be a big help!

\subsection{The properties of sets}
\label{subsec:properties_of_sets}

All sets have some properties in common that we can use to manipulate them.
Examples include membership, equality, inclusion etc.

\subsubsection{Set membership}

To indicate that an element is a member of a set, we use the $\in$ symbol. For
example, to say that the element $true$ is a member of the set $\mathbb{B}$ool,
we would write:

\begin{dmath}
	true \in \mathbb{B}ool
\end{dmath}

Interestingly, we can parse this into English in many ways though. It could mean
any of the following things:

\begin{itemize}
	\item $true$ is an element of the set $\mathbb{B}$ool
	\item $true$ is an member of the set $\mathbb{B}$ool
	\item $true$ is contained in $\mathbb{B}$ool
	\item $\mathbb{B}$ool contains $true$
\end{itemize}

Conversely, to indicate that an element is not a member of a set, we use the
symbol $\notin$:

\begin{dmath}
	sheep \not\in \mathbb{B}ool
\end{dmath}

Note that there is no concept of {\it order} or {\it repetition} in sets. This
means that the following sets are all equal:

\begin{dmath}
	\{1,2,3\}
\end{dmath}
\begin{dmath}
	\{2,3,1\}
\end{dmath}
\begin{dmath}
	\{2,3,1,2\}
\end{dmath}
\begin{dmath}
	\{3,3,3,3,3,2,1\}
\end{dmath}

\subsubsection{Set equality}

Sets are equal if they have exactly the same members. Note that as far as sets
are concerned, duplicate members are treated as just one member.

The notation for set equality is very easy. To say the set $X$ is equal to the
set $Y$, we write:

\begin{dmath}
	X = Y
\end{dmath}

However, you must understand that this is only true if for each element $a$ in
$X$ that element will also be contained in $Y$ and for each element $a$ in Y,
that element will also be contained within $X$:

\marginpar{ Sets with different descriptions can still be equal.
Convince yourself that the set of integers where $y^3 < y$ is equal to the set
of integers where $x < -1$}

\begin{dmath}
	\textrm{For each }a, a \in X \leftrightarrow a \in Y
\end{dmath}

\subsubsection{Set inclusion}

If one set is a subset of another set, all the members of the first set are also
found within the second set. In mathematical terms:

% TODO: Somebody else other than Todd verify this is true and then delete this
% comment please. Peer review ftw!
\begin{dmath}
	{\textrm{For each }a, a \in X \rightarrow a \in Y}
\end{dmath}

The notation for inclusion is $\subseteq$, so in the above example, we would
write:

\marginpar{ If $X \subseteq Y$ and $Y \subseteq X$ then what else an
we say about the relationship between $X$ and $Y$?}

\begin{dmath}
	X \subseteq Y
\end{dmath}

\subsubsection{The empty set}
\label{subsubsec:empty_set}

The empty set is a set that contains no members at all. It's symbol is
$\emptyset$.

Because the empty set has no members, it is a subset of all other sets:

\marginpar{ This is because otherwise $x in \emptyset$ would be true
for some $x$ where $x \not\in A$. This is impossible since there are no elements
in the $\emptyset$.}

\begin{dmath}
	\emptyset \in A
\end{dmath}

\subsubsection{Singleton sets}

For any entity $a$, we can form a set consisting only of $a$:

\begin{dmath}
	\{a\}
\end{dmath}

Be aware, a singleton set is not the same as the element contained within the
set:

\begin{dmath}
	a \neq \{a\}
\end{dmath}

\subsubsection{Set union}

There are several ways of combining multiple sets together to create another
set. One such method is set union, the symbol of which is $\cup$. The union of
two sets is a set containing all the members of {\it both} sets. For example:

\begin{dmath}
	A = \{1, 3, 5, 7, 9\}
\end{dmath}

\begin{dmath}
 	B = \{1, 1, 2, 3, 5, 8, 13\}
\end{dmath}

\begin{dmath}
	A \cup B = \{1, 2, 3, 5, 7, 8, 9, 13\}
\end{dmath}

We could also define the union of two sets mathematically, like so:

\begin{dmath}
	{x \in A \cup B \leftrightarrow x \in A \textrm{ or } x \in B}
\end{dmath}

\subsubsection{Set intersection}

Another way of combining sets is intersection. Intersecting two sets will
produce a set of elements that belong to both of the sets. The symbol for
intersection is $\cap$.

If we defined intersection mathematically, we would do so like this:

\begin{dmath}
	{x \in A \cap B \leftrightarrow x \in A \textrm{ and } x \in B}
\end{dmath}

\subsubsection{Relative complement}

The relative complement of two sets is all the members in the first set that
aren't members of the second set. The symbol for the relative complement is $-$.
Defined mathematically, we get:

\begin{dmath}
	{x \in A - B} \leftrightarrow {x \in A \textrm{ and } x \notin B}
\end{dmath}

\subsubsection{The universal set}
\label{subsubsec:universal_set}

% TODO: Link to De Morgan's laws when we've covered it.
The universal set contains {\it all of the possible elements}. The notation we
use to describe the universal set is $S$. We can define the De Morgan's laws
using the universal set:

\begin{dmath}
	X' = S - X
\end{dmath}

\subsection{Boolean algebra of sets}

If we have a universal set, $S$, and consider only subsets of $S$. Then these
are all the things that we have:

\begin{itemize}
	\item Two distinguished subsets $\emptyset$ and $S$
	\item A unary operation $(.)'$ on such subsets
	\item Two binary operations; $\cap$ and $\cup$ on such subsets
\end{itemize}

This structure of operations and sets is known as {\bf Boolean algebra}. Boolean
algebra has many basic properties that we can exploit in order to manipulate
expression into other forms. Find them on the flashcards that go with these
notes.

%\begin{tabular}{c c c}
%	$X \cup S = S$     &	extreme	&	$X \cap \emptyset = \emptyset$\\
%	$X \cup \emptyset = X$ & neutral &	$X \cap S = X$\\
%	$X \cup Y = Y \cup X$ & commutative & $X \cap Y = Y \cap X$\\
%	$X \cup (Y \cup Z) = (X \cup Y) \cup Z$ & associative & $X \cap (Y \cap Z) = (X \cap Y) \cap Z$\\
%	$X \cup (Y \cap Z) = (X \cup Y) \cap (X \cup Z)$ & distributive & $X \cap (Y \cup Z) = (X \cap Y) \cup (X \cap Z)$\\
%	$X \cup X = X$ & idempotent & $X \cap X = X$\\
%	$X \cup (X \cap Y) = X$ & absorbsion & $X \cap (X \cup Y) = X$\\
%	$(X \cup Y)' = X' \cap Y'$ & De Morgan & $(X \cap Y)' = X' \cup Y'$\\
%	$X \cup X' = S$ & complement & $X \cap X' = \emptyset$ \\
%	$X'' = X$ & involution & $X = X''$ 
%\end{tabular}

\section{Propositional Logic}

\subsection{The logical connectives}

Most of these are very similar to the properties of sets that we came across in
the boolean algebra section. Learn these:

\marginpar{ We use {it inclusive} or in propositional
logic, not {\it exclusive} or.}

\marginpar{ {\it Iff} is an abbreviation for {\it 
if and only iff}.}

\begin{center}
	\begin{tabular}{|c|c|c|}
		\hline
		Name & Symbol & Meaning\\ \hline
		Negation		&	$\neg$		& not\\
		Conjunction		&	$\wedge$	& and\\
		Disjunction		&	$\vee$		& or\\
		Implication		&	$\implies$	& implies\\
		Bi-implication	&	$\iff$		& iff\\
		\hline
	\end{tabular}
\end{center}

All of these symbols are used as infixes, and so go in between two parameters.
An exception to this however, is negation, which is a unary symbol, and is
placed as a prefix before it's argument.

\marginpar{ If a connective takes one parameter, then it's arity is 1, if it
takes two then it has an arity of 2 etc etc}

\subsubsection{The truth tables of the logical connectives}

Using a truth table, we can fully describe the behaviour of the connectives we
have just described in the previous section:

\begin{center}
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		$p_1$& $p_2$& $\neg p_1$& $p_1 \wedge p_2$& $p_1 \vee p_2$\\ \hline
		T& T& F& T &T\\
		T& F& F& F &T\\
		F& T& T& F &T\\
		F& F& T& F &F\\ \hline
	\end{tabular}
	% Split into two so it'll look good on a kindle
	\begin{tabular}{|c|c|c|c|}
		\hline
		$p_1$& $p_2$& $p_1 \implies p_2$& $p_1 \iff p_2$\\ \hline
		T& T& T &T\\
		T& F& F &F\\
		F& T& T &F\\
		F& F& T &T\\ \hline
	\end{tabular}
\end{center}

\paragraph{A note about implication:}
In order to understand why the truth table for implication is as stated above,
consider this example:

\begin{dmath}
	{x > 3 \textrm{ implies } x > 1}
\end{dmath}

Now take a look at the truth table for this expression:

\begin{center}
	\begin{tabular}{|c|c|c|c|}
		\hline
		$x$ & $x > 3$ & $x > 1$ & $x > 3 \implies x > 1$\\ \hline
		4 & T & T & T\\
		2 & F & T & T\\
		0 & F & F & T\\ \hline
	\end{tabular}
\end{center}

As you can see, there is no way to make the first expression ($x>3$) true, but
the second expression ($x>1$) false. Henceforth, the first expression implies
the second expression.

\subsection{The formulae of propositional logic}

In order to build up a piece of propositional logic, we must construct an
expression from {\it atomic formulae} and connectives.\marginpar{An example of
an atomic formula is $p$, or maybe $r_2$. It's any single boolean variable.}

There are three rules we can use to generate a formulae in PL:

\begin{enumerate}
	\item Every atomic formula is a formula of PL
	\item If $A$ is a formula, then so is $\neg A$
	\item If $A$, $B$ are formulae, then so are $(A \wedge B)$, $(A \vee B)$, $(A \implies B)$, $(A \iff B)$
\end{enumerate}

\paragraph{Syntactic conventions} are of course in widespread use. 

For example, when you have written an expression, it is usual to leave off the
outermost parentheses, so $(p \wedge (r \vee q))$ would become $p \wedge (r \vee
q)$.

\marginpar{This second convention is adopted for all associative operations, not
just conjunction and disjunction.}
It is also common to leave out parentheses from repeated uses of conjunction or
disjunction, so $p \wedge (q \wedge r)$ would become $p \wedge q \wedge r$.

\subsection{Truth valuations}

A truth valuation is a list of allocations that define the values of variables
in an expression, where:

\begin{dmath}
	\{p_1=x_1,\dots, p_n=x_n\}
\end{dmath}

\marginpar{An example truth valuation for the expression $p \wedge r$ might be
$\{p=T, r=F\}$, for which the end value would be $F$.}

In order to determine the end value of the PL formula, you must first construct
a truth valuation of it's component atoms, and only then can the formula be
evaluated.

\subsection{Tautologies and contradictions}

If the outcome of a formula is always $T$ for every possible truth valuation,
then the formula is said to be a {\bf tautology}. An example of such an
expression is $p \vee \neg p$.

In contrast, a formula that will yield an outcome of $F$ for every possible
truth valuation is named a {\bf contradiction}. Such an example may be $p \wedge
\neg p$.

If an expression is not a tautology and isn't a contradiction either, then it is
named {\bf satisfiable}.

% TODO: Continue from page 24 of the logic notes

\section{Probability}

\subsection{Sample spaces and events}

A {\bf Sample Space} is a set of all the possible outcomes of an {\it
experiment}. In this sense, an experiment is taken to be some occurrence that
will produce one of many outcomes.

The notation we use for the sample space is $\Omega$.

\begin{dmath}
	\Omega = \{\omega_1, \omega_2, \ldots, \omega_n\}
\end{dmath}

An {\bf event} is a set containing one ore more outcomes of an experiment. Since
all outcomes are included in the set $\Omega$, all events are also subsets of
the sample space. This works both ways, any subset of $\Omega$ is an event. We
use $\omega$ to represent an event.

An event is said to have occurred if the outcome of an experiment contains an
element of that event.

Since all events are sets, it makes sense that we would have an empty set and a
universal set. As with discrete logic (see page~\pageref{subsubsec:empty_set}),
we also use the empty set in probability. Here, we use it to describe an event
that {\it never} occurs. The notation for the empty set is $\emptyset$. We have
already discussed the universal set (see page~\pageref{subsubsec:universal_set})
of probability, it's the sample space, $\Omega$.

\marginpar{If $\Omega$ has $n$ elements, then there are $2^n$ possible events.}

To sum up events an sample spaces, here's an example. If toss a coin, the
following events are generated:

\begin{center}
	\begin{tabular}{|>{\centering\arraybackslash}m{1cm}|m{8cm}|}
		\hline
		{\bf Event} & {\bf Description}\\ \hline
		$\emptyset$ & Nothing happens. This will never occur.\\ \hline
		$\{H\}$     & The coin shows heads.\\ \hline
		$\{T\}$     & The coin shows tails.\\ \hline
		$\Omega$    & The coin shows either heads or tails. This event always occurs.\\
		\hline
	\end{tabular}
\end{center}

\marginpar{Note, events can, of course have multiple elements. If we were
examining a dice throw, we could define the event $A$ to contain all the
outcomes that are even numbers, so $A = \{2,4,6\}$}

\subsection{More set properties}

All of the set operations we discussed in the Discrete Structures section of the
notes still apply here, these can be found in section
~\ref{subsec:properties_of_sets} on page~\pageref{subsec:properties_of_sets}.

However, there are three additional properties that will be useful in this
section.

\subsubsection{The number of items in a set}

We can use the operator $\#$ to find the number of elements in a set. If we have
an event $A$ that contains the elements $\{\omega_1, \omega_2, \omega_3\}$ then
the number of outcomes it contains is three, therefore $\#A = 3$.

\subsubsection{Set difference}

If we have two sets $A$ and $B$, and $B$ is a subset of $A$ (i.e. $B \subset
A$), then we can find the set difference between $A$ and $B$.

The set difference is defined as {\bf all the elements in $A$ that are not in
$B$.} The symbol for set difference is ``$\setminus$''.

Mathematically, this is:

\begin{dmath}
	{A \ B = \{\omega \in \Omega \textrm{ } \vert \textrm{ } \omega \in A \textrm{ and } \omega \not\in B\}}
\end{dmath}

\subsubsection{Disjoint sets}

If two sets are disjoint, then they share no common elements, that is to say
that:

\begin{dmath}
	A \cap B = \emptyset
\end{dmath}

This is important in probability, since if two events are disjoint, then they
will never occur at the same time.

\section{Probability measures}

A probability measure is a mapping between an event and the probability that the
event will occur.

\begin{dmath}
	\mathbb{P} : \{\textrm{\it Collection of all events}\} \rightarrow [0,1]
\end{dmath}

This defines $\mathbb{P}$ as a number between $0$ and $1$ (i.e. a probability).
Since a probability measure is defined for {\it all} events that can occur, then
the following are true:

\begin{itemize}
	\item $\mathbb{P}(\Omega) = 1$
	\item If $A$ and $B$ are disjoint events then $\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B)$
	\item If $\mathbb{P}(A) = 0$ then $A$ will never occur.
	\item If $\mathbb{P}(A) = 1$ then $A$ will always occur.
\end{itemize}

\marginpar{If $\mathbb{P}(A) = 1$, then that doesn't mean that $A = \Omega$,
since there could be other events $\omega$ where $\mathbb{P}(\omega) = 0$}

In order to verify whether any given mapping is a probability measure, you must
check it against the first two of the above bullets; that the sum of all the
mappings is $1$ and the mapping of the union of any two disjoint events is the
same as the sum of the separate mappings of the disjoint events.

\subsection{Indicator functions}

An indicator function will yield a value of $1$ if an element $\omega$ is inside
a set, and a value of $0$ if the element is not inside the set. It can be
defined as follows:

\begin{dmath}
	1_A(\omega_i) = \begin{cases} 
						1\textrm{ if }\omega_i \in A\\
						0\textrm{ if }\omega_i \not\in A
					\end{cases}
\end{dmath}

We can therefore define the probability of an event $A$ to be the sum of all the
probabilities of the events inside $A$:

\begin{dmath}
	\mathbb{P}(A) = \sum\limits_{i=1}^n1_A(\omega_i)p_i
\end{dmath}

\marginpar{Note that $n$ is the number of elements inside $A$.}

\section{Computing the probability of equally likely functions}

If we have a sample space $\Omega = \{ \omega_1, \omega_2, \dots, \omega_n \}$
where each element is equally likely to occur, then we can say that $p_i =
\mathbb{P}(\{\omega_i\})$. Since all the elements are equally likely to occur,
we can say that $p_1 = p_2 = \dots = p_i$ and also that $p_1 + p_2 + \dots + p_i
= 1$.

Using ideas from the previous section, we can find the probability of any event
$A$ inside a sample space where all elements are equally likely. To do this, all
we need to do is find the sum of all the elements in the sample space, but
multiply the elements by the indicator function of $A$ before we add them onto
the sum:

\begin{dmath}
	\mathbb{P}(A) = \sum\limits_{i=1}^{n} 1_A(\omega_i)p_i
\end{dmath}

However, since all the elements inside $\Omega$ are equally likely, that must
mean that for any event $\omega_i$, it's probability must be $\frac{1}{n}$ where
$n$ is the number of elements inside the sample space. If we take this into
account, we can formulate the following formula:

\begin{dmath}
	\mathbb{P}(A) = \frac{1}{n}\sum\limits_{i=1}^{n} 1_A(\omega_i)
\end{dmath}


However, we can make this even more simple; if we recognise that any element in
$A$ has the same probability of occurring as any element in $\Omega$, then it's
easy to realise that the probability of $A$ occurring will be equal to the
relationship between sizes of the sets $A$ and $\Omega$:

\begin{dmath}
	\mathbb{P}(A) = \frac{\#A}{\#\Omega}
\end{dmath}

\subsection{Finding the binomial coefficient}

The binomial coefficient is represented as $n \choose k$, both $n$ and $k$ are
integers. It is pronounced $n$ {\it choose} $k$.

\begin{dmath}
	{n \choose k} = \frac{n!}{k!(n-k)!}
\end{dmath}

\subsection{Choosing items}

If we have a set of three items $a, b$ and $c$, then how many different ways can
we choose two of those three items from the set?

This depends on two things. Does the order of the items matter, and can we
choose an item twice?

If the order is important and we can choose an item many times, then we can
choose the following items:

\begin{dmath}
	(a,a), (a,b), (a,c), (b,a), (b,b), (b,c), (c,a), (c,b), (c,c)
\end{dmath}

If the order is not important, then we have:

\begin{dmath}
	(a,a), (a,b), (a,c), (b,b), (b,c), (c,c)
\end{dmath}

If the order is important, but we can't choose an item twice, we get:

\begin{dmath}
	(a,b), (a,c), (b,a), (b,c), (c,a), (c,b)
\end{dmath}

Finally, if the order is not important and the items cannot be selected twice,
then:

\begin{dmath}
	(a,b), (a,c), (b,c)
\end{dmath}

In order to calculate the number of possible different selections we can make in
these different cases, we can use this table:

\begin{center}
\begin{tabular}{|c|c|c|}
	\hline
	& \multicolumn{2}{c|}{Order important?}\\
	\cline{2-3}
	& Yes & No\\ \hline
	Without replacement & $\frac{n!}{(n-k)!}$ & $n \choose k$\\ \hline
	With replacement & $n^k$ & Complicated\\ \hline
\end{tabular}
\end{center}

It's easy to verify that these are true; since:

\begin{itemize}
	\item With replacement, order important:
	\begin{dmath}
		n^k = 3^2 = 9
	\end{dmath}
	\item Without replacement, order important:
	\begin{dmath}
		\frac{n!}{(n - k)!} = 	\frac{3!}{(3 - 2)!} = 6
	\end{dmath}
	\item Without replacement and order is not important:
	\begin{dmath}
		{n \choose k} = \frac{n!}{k(n - k)!} = \frac{3!}{2(3 - 2)!} = \frac{6}{2} = 3
	\end{dmath}

\end{itemize}

\marginpar{See chapter 2 in the course provided notes for (copious) examples of
the content covered in this section.}


\section{Conditioning}

If an experiment is performed where we already know that a certain event will
occur, then we can factor in an additional factor into our probabilistic
theories. This factor could be called a condition.

An example is throwing a dice. If we define the event $B = \{5, 6\}$ then there
is a probability of $\frac{1}{3}$ that the event $B$ will occur. If we know in
advance that $B$ will occur, then the probabilities that the events outside $B$
will occur suddenly drop to zero:

\begin{dmath}
	{\mathbb{P}(\{1\}) = \dots = \mathbb{P}(\{4\}) = 0}
\end{dmath}

The probability that $B$ will occur is $1$, therefore the probability that
either event in $B$ will occur is $\frac{1}{2}$.

To clarify the following two things have just happened:

\begin{itemize}
	\item All outcomes not in the event $B$ have a probability $0$.
	\item All outcomes in the event $B$ have their probability {\it scaled} by a
	factor of $\frac{1}{\mathbb{P}(B)}$.
\end{itemize}

In a more general case, the probability that any event $A$ occurs, given that
the event $B$ occurs is:

\begin{dmath}
	\frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)}
\end{dmath}

The notation we use for conditional probability (i.e. the probability an event
$A$ will occur given that the event definitely will $B$ occur) is:

\begin{dmath}
	\mathbb{P}(A|B)
\end{dmath}

\marginpar{It's correct to say that the definition of $A$ given $B$ is a
probability measure. The probability measure would be concentrated on the event
$B$ rather than the whole sample space $Omega$ since all events outside $B$ are
given the probability $0$.}

\subsection{Independent events}

If the probability of the event $A$ does not change when we add the conditional
that an event $B$ will certainly occur and $\mathbb{P}(B) \ge 0$, then the
events $A$ and $B$ are independent. This could be described as:

\begin{dmath}
	{\mathbb{P}(A) = \mathbb{P}(A|B)}
\end{dmath}

We can manipulate this mathematical definition of independence using the
equations we described in the at the start of the conditionals section:

\begin{dmath}
	{\mathbb{P}(A) = \mathbb{P}(A|B)} \iff {\mathbb{P}(A) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)}} \iff {\mathbb{P}(A)\mathbb{P}(B) = \mathbb{P}(A \cap B)}
\end{dmath}

Henceforth, we often take the last of these equations as our definition for
independence.

Of course, it's easy to do the following too:

\begin{dmath}
	{\mathbb{P}(A)\mathbb{P}(B) = \mathbb{P}(A \cap B)} \iff {\mathbb{P}(B) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(A)}} \iff {\frac{\mathbb{P}(B \cap A)}{\mathbb{P}(A)}} \iff {\mathbb{P}(B|A)}\\	
\end{dmath}

\begin{dmath}
	{\mathbb{P}(A|B) \iff \mathbb{P}(B|A)}
\end{dmath}

So, an event is independent of another event if knowledge that one event occurs
won't give you any extra information about how likely it is that the other event
will occur. This doesn't mean that the events are disjoint (unless the
probability of either was $0$).

\subsection{Partitions}

Partitions are sections of a sample space that:

\begin{itemize}
	\item Don't overlap.
	\item Include all elements inside the sample space between them.
\end{itemize}

So, suppose I had partitions $E_0 \dots E_n$, the following would hold:

\begin{itemize}
	\item $E_i \cap E_i = \emptyset$ for and $i$ and $j$
	\item $E_0 \cup E_1 \cup \dots \cup E_n = \Omega$
\end{itemize}

This means that all partitions are mutually disjoint.

\marginpar{The simplest partition is to take an event $A$ and it's complement
$A^c$.}

Note that the probability of the union of any two partitions will be the sum of
the probability of the separate partitions, since all partitions are disjoint.

\subsection{The law of total probability}

The law of total probability splits any event $A$ up in terms of the partitions
in the sample space:

\begin{dmath}
	A = (A \cap E_i) \cup (A \cap E_2) \cup \dots \cup (A \cap E_n)
\end{dmath}

We can write this in terms of probabilities:

\begin{dmath}
	\mathbb{P}(A) = \mathbb{P}(A|E_1)\mathbb{P}(E_1) + \dots + \mathbb{P}(A|E_n)\mathbb{P}(E_n)
\end{dmath}

\subsection{Bayes Theorem}

The derivation of Bayes theorem is quite easy; start with an event partitioned
into $m$ partitions, then take $\mathbb{P}(E_i|A)$ and use first the definition
of conditional probability, then the multiplicative law, then the law of total
probability. The process is described mathematically below:

\begin{dmath}
	\mathbb{P}(E_i|A) = \frac{\mathbb{P}(E_i \cap A)}{\mathbb{P}(A)} = \frac{\mathbb{P}(A|E_i)\mathbb{P}(E_i)}{\mathbb{P}(A)} = \frac{\mathbb{P}(A|E_i)\mathbb{P}(E_i)}{\mathbb{P}(A|E_1)\mathbb{P}(E_1) + \dots + \mathbb{P}(A|E_m)\mathbb{P}(E_m)}
\end{dmath}

Bayes theorem is good if you have the probability of some event $A$ that depends
on the condition of the event $B$ happening (i.e. you know $\mathbb{P}(A|B)$,
but you instead want to know $\mathbb{P}(B|A)$.

\subsubsection{The complementary law for conditional probabilities}

The complementary law states that:

\begin{dmath}
	\mathbb{P}(A|B) = 1 - \mathbb{P}(A^c|B)
\end{dmath}

\section{Random variables}

A random variable is a mapping between the sample space $\Omega$ to real numbers
($\mathbb{R}$). A random variable is usually denoted by $X$.

\begin{dmath}
	X : \Omega \rightarrow \mathbb{R}
\end{dmath}

This means that every outcome in the sample space corresponds to a real number.
The range of the random variable is very intuitive; if we were throwing a dice,
then the range would be $\{1, 2, \dots, 6\}$.

The sum of the probabilities of the random variable is always equal to $1$:

\begin{dmath}
	\sum\limits_{i=1}^m\mathbb{P}(X=r_i) = 1
\end{dmath}

\subsection{Constructing new random variables from existing ones}
\label{subsec:new_random_vars}
Creating a random variable from another random variable is fairly easy; it's
basically a composite function. If we have a random variable $X$ and a function
$f$ then:

\begin{dmath}
	Y(\omega) = f(X(\omega)) \textrm{ for all $\omega \in \Omega$}
\end{dmath}

Note that the range of the new function ($Y$) may be different from the range of
the old one ($X$).

\subsection{Probability mass functions}

Usually abbreviated to {\it pmf} a probability mass function is a function
(denoted by $p$) that contains information regarding the probabilities of $X$ in
given ranges.

Since the output of a {\it pmf} is a probability, the range of a {\it pmf} is
always $[0,1]$.

Mathematically, the probability mass function of a random variable $X$ is
defined as:

\begin{dmath}
	p(r_i) := \mathbb{P}(X = r_i) \textrm{ for all $i > 1$}
\end{dmath}

\marginpar{The sum of all the values in a {\it pmf} function is always $1$.}

\subsection{Cumulative distribution functions}

A cumulative distribution function {\it cdf} is similar to a {\it pmf} except
that:

\begin{itemize}
	\item The value of the {\it cdf} is the sum of the {\it pmf} up to that 
	point.
	\item A {\it cdf} can be generated for any function, not just discrete ones
	like a {\it pmf} can.
\end{itemize}

However, both the {\it cdf} and the {\it pmf} share the same range. The
definition of {\it cdf} is:

\begin{dmath}
	{F(x) = \mathbb{P}(X \leq x)} \textrm{ for all $x \in \mathbb{R}$}
\end{dmath}

A graph of a {\it cdf} function contains all the information about the random
variable it has mapped. We can deduce it's range, the {\it pmf} and where the
graph jumps. Note that black dots on the graph indicate where a value is, and
white dots at the same $x$ coordinate show where the value isn't.

\subsection{The mean of a random variable}

Finding the average value of a random variable is comparable to doing so for a
sequence of numbers where each number has a weight. If the numbers are numbered
$\alpha_1 \dots \alpha_n$ and their weights are numbered $\omega_1 \dots
\omega_n$ then the average value would be:

\begin{dmath}
	\textrm{Average value: } = \frac{\omega_1\alpha_1 + \dots + \omega_n\alpha_n}{\omega_1 + \dots + \omega_n}
\end{dmath}

Note that the mean is represented by $\mathbb{E}$ so:

\begin{dmath}
	\mathbb{E} = \frac{\omega_1\alpha_1 + \dots + \omega_n\alpha_n}{\omega_1 + \dots + \omega_n}
\end{dmath}

In this analogy, then the values for $\alpha$ would be members of the range of
$X$ and the values of $\omega$ would be the probabilities that these values
would occur:

\begin{dmath}
	\mathbb{E}(X) = \frac{\mathbb{P}(X = r_1) \cdot r_1 + \dots + \mathbb{P}(X = r_n) \cdot r_n}{\mathbb{P}(X = r_1) + \dots + \mathbb{P}(X = r_n)}
\end{dmath}

However, since the denominator of this fraction is merely the sum of the
probabilities of each of the elements in the range of $X$, it will always equal
$1$. Therefore:

\begin{dmath}
	\mathbb{E}(X) = {\mathbb{P}(X = r_1) \cdot r_1 + \dots + \mathbb{P}(X = r_n) \cdot r_n} = {\sum\limits_{i=1}^{n} r_i \mathbb{P}(X = r_i)}
\end{dmath}

In order to define the mean of a function of a random variable (as described in
section~\ref{subsec:new_random_vars}), we don't need to apply the function to
the probability of each element occurring, only to the element itself:

\begin{dmath}
	\mathbb{E}(f(X)) = {\sum\limits_{i=1}^{n} f(r_i) \mathbb{P}(X = r_i)}
\end{dmath}

Of course, if the random variable $Y = f(X(r_i))$ then you can just find
the average of $Y$ instead:

\begin{dmath}
	\mathbb{E}(Y) = {\sum\limits_{i=1}^{n} r_i \mathbb{P}(Y = r_i)}
\end{dmath}

We can say two more things about the means of random variables:

\begin{itemize}
	\item If the random variable only has one element in it's range, then the mean of the random variable must be that element.
	\item For any $a, b \in \mathbb{R}$ we have
	\begin{dmath}
		\mathbb{E}(aX + b) = a\mathbb{E}(X) + b
	\end{dmath}
\end{itemize}

\subsection{The varience and standard deviation of a random variable}

